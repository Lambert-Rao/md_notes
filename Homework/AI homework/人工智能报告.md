# 人工智能实验报告

[toc]

## 1. 环境搭建

   本次实验采用华为云ModelArts平台作为实验环境，使用MindSpore作为深度学习框架。首先，我们在华为云上创建一个ModelArts实例，然后在ModelArts中配置Notebook环境，选择MindSpore作为深度学习框架。在Notebook环境中，我们编写实验代码并执行，完成实验内容。

## 2. 实验内容

   以下是每个实验的具体内容：

### 2.1 新冠肺炎广东地区病例数据分析

#### 2.1.1 数据集简介

1. 数据内容：本实验使用的数据集包含了广东地区新冠肺炎的统计数据。
2. 特征数量：共有18个特征，其中有5个有效特征，分别为确诊人数，疑似人数，治愈人数，死亡人数和更新时间。
3. 样本总量：数据集共包含6888个有效样本。
4. 数据清洗过程：将时间转化为分钟时间戳，并构建新的时间特征。

#### 2.1.2 算法、模型介绍

1. 训练模型：多项式回归（Polynomial Regression），指数形式的线性回归（Exponential Linear Regression）和随机森林回归（Random Forest Regressor）。
2. 使用的损失函数：负均方误差（neg_mean_squared_error），该损失函数用于评估回归问题。
3. 评估方法：交叉验证（CV），使用5折交叉验证（cv=5），评估负均方误差（MSE）作为评估指标。

### 2.2 前列腺癌回归预测

#### 2.2.1 数据集简介

1. 数据内容：本实验使用的数据集是Prostate Cancer dataset，包含了前列腺癌患者的临床数据和基因表达数据。
2. 特征数量：共有9个特征，分别是年龄、PSA（前列腺特异抗原）、PCa（前列腺癌诊断）、体积、外观、肺结节、骨扫描、CT、MRI等。
3. 样本总量：数据集共包含97个样本。
4. 数据异常情况：部分样本的PGG45特征存在异常值。
5. 数据清洗过程：对于异常值，使用IQR方法进行处理。

#### 2.2.2 算法、模型介绍

1. 训练模型：线性回归（LinearRegression），随机梯度下降回归（SGDRegressor）和岭回归（Ridge）。
2. 使用的损失函数：负均方误差（neg_mean_squared_error），该损失函数用于评估回归问题。
3. 评估方法：交叉验证（CV）, 使用10折交叉验证（cv=10），同时评估负均方误差（MSE）和决定系数（R^2）作为评估指标。

### 2.3 MNIST手写数字识别

#### 2.3.1 数据集简介

1. 数据内容：MNIST 数据集包含了大量手写数字图片和对应的标签。图片是28x28的灰度图像,标签是0-9的数字,表示图片中写的是哪个数字。MNIST 数据集是机器学习入门的 “Hello World” 。这个数据集非常适合作为测试模型性能的数据集。
2. 样本总量：MNIST 数据集包含了 60,000 个训练样本和 10,000 个测试样本。
3. 样本类别数量：10个

#### 2.3.2 算法、模型介绍

1. 训练模型：LeNet5模型
2. 网络结构：两次卷积层conv1和conv2,池化层pool,全连接层fc1/fc2/fc3,激活函数relu/sigmoid,Dropout层等
3. 优化算法：使用SGD优化器进行优化,设置学习率和动量参数。
4. 训练方式：分别以ReLU/Sigmoid为激活函数,MSELoss/CrossEntropyLoss为损失函数,dropout与否的不同配置
5. 评估方式：精度

### 2.4 USPS 美国邮编手写数字数据集

#### 2.4.1 数据集简介

1. 数据内容：USPS 美国邮编手写数字数据集包含了大量邮编手写数字图片和对应的标签。图片是16x16的灰度图像，标签是0-9的数字，表示图片中写的是哪个数字。USPS 数据集常用于机器学习和计算机视觉领域，尤其是在手写数字识别任务中。
2. 样本总量：USPS 数据集包含了 7,291 个训练样本和 2,007 个测试样本。
3. 样本类别数量：10个

#### 2.4.2 算法、模型介绍

1. 训练模型：LeNet-5模型
2. 网络结构：LeNet-5包括两个卷积层conv1和conv2，两个池化层pool1和pool2，以及三个全连接层fc1、fc2和fc3。激活函数可以选择ReLU或Sigmoid，还可以选择在网络中添加Dropout层，以减少过拟合的风险。
3. 优化算法：使用SGD（随机梯度下降）优化器进行优化，可以设置学习率和动量参数以提高模型性能。
4. 训练方式：分别以ReLU和Sigmoid为激活函数，MSELoss和CrossEntropyLoss为损失函数，以及选择是否使用Dropout的不同配置进行训练。
5. 评估方式：使用准确率（Accuracy）作为评估模型在USPS手写数字数据集上的性能指标。

## 3. 实验结果

> 对于回归问题，我们使用了R2和均方根误差（RMSE）作为评价指标。
> 对于分类问题，我们使用了混淆矩阵、召回率和准确率作为评价指标。
> 同时统计了模型训练时长和模型文件大小。

### 3.1新冠肺炎广东省病例回归实验结果

#### 	确诊病例预测

   1. 随机森林回归

      Best RMSE mean: 259.5035,
      Best R^2:  -2.8160,
      Training time:186.1665ms

   2. 多项式回归

      Best RMSE mean: 502.6367,
      Best R^2:  -720.0006,
      Training time: 1.8444ms

   3. 指数回归

      Best RMSE mean: 502.6367,
      Best R^2:  -720.0006,
      Training time: 0.8940ms

  以RMSE为评价指标，最好的算法是随机森林，模型文件大小为2.9 MiB。

![covid guangdong1](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304282004527.png)

![covid guangdong2](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304282004528.png)


#### 	痊愈病例预测

   1. 随机森林回归

      Best MSE mean: 15575.1015,
      Best R^2:  -2.2302,
      Training time: 238.6837ms

   2. 多项式回归

      Best MSE mean: 21527.8782,
      Best R^2:  -296.2089,
      Training time: 11.9078ms

以MSE作为评价指标，最好的算法是随机森林算法，模型文件大小为2.9 MiB。

![covid guangdong3](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304282004532.png)

![covid guangdong4](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304282019772.png)

### 3.2 前列腺癌回归实验结果

1. 线性回归模型：
   Best MSE: 0.5491,
   Best R^2: 0.3256,
   Training time: 15.06 ms
2. 随机梯度下降回归：
   Best MSE: 0.5296, 
   Best R^2: 0.3417, 
   Best parameters: {'alpha': 0.0001, 'eta0': 0.1, 'learning_rate': 'invscaling', 'max_iter': 500},
   Training time: 1081.07 ms
3. 岭回归：
   Best MSE: 0.5455,
   Best R^2: 0.3317,
   Best parameters: {'alpha': 1.0}, 
   Training time: 57.19 ms

以mse作为主要评价指标，可以看出最好的模型是随机梯度下降回归，其模型大小为31 B，训练时间为1081.07 ms.

### 3.3 MNIST手写数字识别实验结果

Training with ReLU Mean Squared Error without Dropout:

Loss: 3.422729299120185
Accuracy: 98.50761217948718 %
Time：150s

![1](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281357281.png)

![2](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358220.png)

Training with ReLU Cross Entropy without Dropout:

Loss: 2764.0959190130234
Accuracy: 98.3173076923077 %
Time：140s

![3](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358394.png)

![4](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358889.png)

Training with Sigmoid Mean Squared Error without Dropout:

Loss: 26.800182914128527
Accuracy: 91.796875 %
Time：285s

![5](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358043.png)

![6](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358788.png)

Training with Sigmoid Cross Entropy without Dropout:

Loss: 3000.372096657753
Accuracy: 86.93910256410257 %
Time：130s

![7](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358162.png)

![8](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281359069.png)

Training with ReLU Mean Squared Error with Dropout:

Loss: 4.596175650123552
Accuracy: 98.40745192307692 %
Time：144s

![9](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358600.png)

![10](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281359432.png)

Training with ReLU Cross Entropy with Dropout:

Loss: 2954.7182821035385
Accuracy: 88.53165064102564 %
Time：134s

![11](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358853.png)

![12](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281359406.png)

Training with Sigmoid Mean Squared Error with Dropout:

Loss: 167.63514412939548
Accuracy: 17.728365384615383 %
Time：137s

![13](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281359177.png)

![14](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358741.png)

Training with Sigmoid Cross Entropy with Dropout:

Loss: 2843.033079981804
Accuracy: 95.55288461538461 %
Time：133s

![15](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281358671.png)

![16](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281359705.png)

其中最高精度为ReLU激活函数，MSE损失函数，不设置Dropout正则化。

### 3.4 USPS手写数字识别结果

train_lenet5_model(activation='leaky_relu', loss_function='ce', num_epochs=30, batch_size=64, learning_rate=0.001, dropout_rate=0.5, patience=2)

Epoch 25/30, Loss: 0.0928,  Accuracy: 97.48%
Test Loss: 0.2454, Test Accuracy:  93.97%
Epoch 25/30: Early stopping.  Best test loss: 0.24542160201235674.
Total training time: 18.98 seconds
![1](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281646065.png)




train_lenet5_model(activation='leaky_relu', loss_function='ce', num_epochs=30, batch_size=64, learning_rate=0.01, dropout_rate=0.1, patience=2)

Epoch 20/30, Loss: 0.0082,  Accuracy: 99.79%
Test Loss: 0.2181, Test Accuracy:  95.86%
Epoch 20/30: Early stopping.  Best test loss: 0.2070933171944489.
Total training time: 15.68 seconds

![2](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281646067.png)
train_lenet5_model(activation='sigmoid', loss_function='ce', num_epochs=30, batch_size=64, learning_rate=0.01, dropout_rate=0.0, patience=2)

Epoch 25/30, Loss: 0.0268,  Accuracy: 99.41%
Test Loss: 0.2188, Test Accuracy:  94.17%
Epoch 25/30: Early stopping.  Best test loss: 0.21879403747152537.
Total training time: 19.52 seconds

![3](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281646069.png)
train_lenet5_model(activation='relu', loss_function='ce', num_epochs=30, batch_size=64, learning_rate=0.01, dropout_rate=0.0, patience=2)

Epoch 20/30, Loss: 0.0067,  Accuracy: 99.89%
Test Loss: 0.2467, Test Accuracy:  95.76%
Epoch 20/30: Early stopping.  Best test loss: 0.2442517851741286.
Total training time: 34.97 seconds

![4](https://raw.githubusercontent.com/Limpol-Rao/image_host/main/img/202304281646070.png)


## 4. 进一步改进的设想

   为了进一步提高模型的性能，对于每个实验我们可以尝试以下改进方法：

### 4.1 广东疫情预测实验的改进

1. 尝试使用更多的模型：在原有的模型基础上，可以尝试使用K近邻回归（KNeighborsRegressor）、支持向量回归（SVR）等其他回归算法，通过对比各个模型的性能，找到最适合当前数据的模型。

2. 特征选择和降维：在训练模型之前，可以尝试对特征进行选择和降维。例如，使用主成分分析（PCA）进行降维，从而减少特征之间的多重共线性，提高模型训练效率并降低过拟合风险。

3. 优化超参数搜索方法：在进行网格搜索时，可以考虑使用随机搜索（RandomizedSearchCV），相较于网格搜索，随机搜索能更快地找到一个好的参数组合，同时也减少了计算资源的消耗。

通过实施这些改进设想，我们可以在不同方面优化香港疫情预测问题的解决方案，从而提高预测的准确性和模型的可靠性。

### 4.2 前列腺癌回归改进

1. 可以尝试使用更多的模型，例如K近邻回归（KNeighborsRegressor），支持向量回归（SVR）等。
2. 在训练模型之前，可以尝试对特征进行选择和降维（例如，使用PCA）。
3. 在进行网格搜索时，可以考虑使用随机搜索（RandomizedSearchCV），这将能更快地找到一个好的参数组合。
4. 在评估指标上，可以使用均方根误差（RMSE）代替MSE，因为RMSE与原始目标变量具有相同的单位，更具有实际意义。

### 4.3 MNIST手写数字识别

1. 调整优化器和学习率策略：尝试使用其他优化器，如Adam、RMSprop等，以查找最佳优化方法。同时，可以调整学习率，例如采用自适应学习率调整策略，如学习率衰减、周期性学习率等。

2. 使用数据增强：对训练数据进行数据增强，如随机旋转、缩放、翻转等。这可以增加模型泛化能力，提高对新数据的预测准确性。

3. 调整网络结构：尝试调整网络结构，例如增加卷积层和池化层的数量、调整卷积核大小和步长等。这有助于找到更适合解决手写数字识别问题的网络结构。

4. 使用批归一化（Batch Normalization）：在卷积层和全连接层之后添加批归一化层，可以加速网络收敛，提高模型性能。

5. 早停法（Early Stopping）：在训练过程中，监控验证集的损失，当损失不再显著下降时，停止训练。这有助于防止模型过拟合，并节省计算资源。

6. 使用更复杂的模型：尝试使用更复杂的模型，如ResNet、VGG等深度学习模型。这些模型可能具有更强的特征提取能力，从而提高预测准确性。

通过实施这些改进设想，我们可以在不同方面优化MNIST手写数字识别问题的解决方案，从而提高预测准确性和模型的可靠性。

### 4.4 USPS手写邮编数字识别

1. 数据增强：为了增加数据的多样性和数量，可以对训练数据进行旋转、平移、缩放等变换，从而提高模型的鲁棒性和泛化能力。
2. 数据集的多样性：可以通过增加数据集中的不同字体、不同大小、不同位置和不同背景颜色等来提高数据集的多样性，从而提高模型的泛化能力。
3. 模型融合：可以采用多个模型进行融合，比如将多个CNN模型的结果进行加权平均或投票，从而提高识别精度。
4. 模型优化：可以采用自适应学习率、权重衰减、梯度裁剪等方法来优化模型训练过程，从而提高模型的性能。
5. 超参数调节：可以通过网格搜索、随机搜索等方法来寻找最佳的超参数组合，以提高模型的准确性。
6. 模型压缩：可以采用模型剪枝、量化等技术来减小模型的体积和计算量，从而提高模型的运行速度和效率。
